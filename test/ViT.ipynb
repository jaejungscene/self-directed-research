{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights.\n",
      "the number of model parameters: 86,859,496\n",
      "ViT(\n",
      "  (patch_embedding): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (positional_embedding): PositionalEmbedding1D()\n",
      "  (transformer): Transformer(\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (1): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (2): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (3): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (4): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (5): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (6): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (7): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (8): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (9): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (10): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (11): Block(\n",
      "        (attn): MultiHeadedSelfAttention(\n",
      "          (proj_q): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_k): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_v): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (drop): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (pwff): PositionWiseFeedForward(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (drop): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_vit import ViT\n",
    "model_name = 'B_16_imagenet1k'\n",
    "model = ViT(model_name, pretrained=True)\n",
    "print('the number of model parameters: {:,}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /opt/conda/lib/python3.8/site-packages/torchvision/image.so: undefined symbol: _ZNK3c1010TensorImpl36is_contiguous_nondefault_policy_implENS_12MemoryFormatE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "50000\n",
      "10000\n",
      "torch.Size([3, 32, 32])\n",
      "tensor(2.0926)\n",
      "tensor(-1.9887)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "dic = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
    "        5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "start_time = time.time()\n",
    "batch_size = 128\n",
    "learning_rate = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # transforms.Resize([224, 224]),\n",
    "    transforms.RandomCrop(32, padding = 4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467),\n",
    "                          std=(0.2471, 0.2436, 0.2616))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4824, 0.4467),\n",
    "                          std=(0.2471, 0.2436, 0.2616))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='/home/ljj0512/private/dataset/cifar-10',\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root='/home/ljj0512/private/dataset/cifar-10',\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,\n",
    "                                          num_workers=2)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][0].max())\n",
    "print(train_dataset[0][0].min())\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.imshow(train_dataset[0][0].permute(1,2,0))\n",
    "# plt.show()\n",
    "\n",
    "# size = 1\n",
    "# x = transforms.RandomCrop(224, padding = size)(train_dataset[0][0])\n",
    "# print(x.shape)\n",
    "# plt.imshow(x.permute(1,2,0))\n",
    "# plt.show()\n",
    "# for i in range(4):\n",
    "#     print(x[:,0+i,0+i])\n",
    "#     print(x[:,-1-i,0+i])\n",
    "#     print(x[:,0+i,-1-i])\n",
    "#     print(x[:,-1-i,-1-i])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearProjection(nn.Module):\n",
    "\n",
    "    def __init__(self, patch_vec_size, num_patches, latent_vec_dim, drop_rate):\n",
    "        super().__init__()\n",
    "        self.linear_proj = nn.Linear(patch_vec_size, latent_vec_dim)\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, latent_vec_dim))\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches+1, latent_vec_dim))\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = torch.cat([self.cls_token.repeat(batch_size, 1, 1), self.linear_proj(x)], dim=1)\n",
    "        x += self.pos_embedding\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class MultiheadedSelfAttention(nn.Module):\n",
    "    def __init__(self, latent_vec_dim, num_heads, drop_rate):\n",
    "        super().__init__()\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.num_heads = num_heads\n",
    "        self.latent_vec_dim = latent_vec_dim\n",
    "        self.head_dim = int(latent_vec_dim / num_heads)\n",
    "        self.query = nn.Linear(latent_vec_dim, latent_vec_dim)\n",
    "        self.key = nn.Linear(latent_vec_dim, latent_vec_dim)\n",
    "        self.value = nn.Linear(latent_vec_dim, latent_vec_dim)\n",
    "        self.scale = torch.sqrt(latent_vec_dim*torch.ones(1)).to(device)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        q = self.query(x)\n",
    "        k = self.key(x)\n",
    "        v = self.value(x)\n",
    "        q = q.view(batch_size, -1, self.num_heads, self.head_dim).permute(0,2,1,3)\n",
    "        k = k.view(batch_size, -1, self.num_heads, self.head_dim).permute(0,2,3,1) # k.t\n",
    "        v = v.view(batch_size, -1, self.num_heads, self.head_dim).permute(0,2,1,3)\n",
    "        attention = torch.softmax(q @ k / self.scale, dim=-1)\n",
    "        x = self.dropout(attention) @ v\n",
    "        x = x.permute(0,2,1,3).reshape(batch_size, -1, self.latent_vec_dim)\n",
    "\n",
    "        return x, attention\n",
    "\n",
    "class TFencoderLayer(nn.Module):\n",
    "    def __init__(self, latent_vec_dim, num_heads, mlp_hidden_dim, drop_rate):\n",
    "        super().__init__()\n",
    "        self.ln1 = nn.LayerNorm(latent_vec_dim)\n",
    "        self.ln2 = nn.LayerNorm(latent_vec_dim)\n",
    "        self.msa = MultiheadedSelfAttention(latent_vec_dim=latent_vec_dim, num_heads=num_heads, drop_rate=drop_rate)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.mlp = nn.Sequential(nn.Linear(latent_vec_dim, mlp_hidden_dim),\n",
    "                                 nn.GELU(), nn.Dropout(drop_rate),\n",
    "                                 nn.Linear(mlp_hidden_dim, latent_vec_dim),\n",
    "                                 nn.Dropout(drop_rate))\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.ln1(x)\n",
    "        z, att = self.msa(z)\n",
    "        z = self.dropout(z)\n",
    "        x = x + z\n",
    "        z = self.ln2(x)\n",
    "        z = self.mlp(z)\n",
    "        x = x + z\n",
    "\n",
    "        return x, att\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, patch_vec_size, num_patches, latent_vec_dim, num_heads, mlp_hidden_dim, drop_rate, num_layers, num_classes):\n",
    "        super().__init__()\n",
    "        self.patchembedding = LinearProjection(patch_vec_size=patch_vec_size, num_patches=num_patches,\n",
    "                                               latent_vec_dim=latent_vec_dim, drop_rate=drop_rate)\n",
    "        self.transformer = nn.ModuleList([TFencoderLayer(latent_vec_dim=latent_vec_dim, num_heads=num_heads,\n",
    "                                                         mlp_hidden_dim=mlp_hidden_dim, drop_rate=drop_rate)\n",
    "                                          for _ in range(num_layers)])\n",
    "\n",
    "        self.mlp_head = nn.Sequential(nn.LayerNorm(latent_vec_dim), nn.Linear(latent_vec_dim, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        att_list = []\n",
    "        x = self.patchembedding(x)\n",
    "        for layer in self.transformer:\n",
    "            x, att = layer(x)\n",
    "            att_list.append(att)\n",
    "        x = self.mlp_head(x[:,0])\n",
    "\n",
    "        return x, att_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE 10 GPUs!\n",
      "USE index 2 GPU\n",
      "Epoch: 0 | Batch_idx: 0 |  Loss: (2.4759) | Acc: (13.28%) (17/128)\n",
      "Epoch: 0 | Batch_idx: 10 |  Loss: (13.9554) | Acc: (12.36%) (174/1408)\n",
      "Epoch: 0 | Batch_idx: 20 |  Loss: (8.9199) | Acc: (12.24%) (329/2688)\n",
      "Epoch: 0 | Batch_idx: 30 |  Loss: (6.8371) | Acc: (12.00%) (476/3968)\n",
      "Epoch: 0 | Batch_idx: 40 |  Loss: (5.7325) | Acc: (11.34%) (595/5248)\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (5.0583) | Acc: (11.18%) (730/6528)\n",
      "Epoch: 0 | Batch_idx: 60 |  Loss: (4.6067) | Acc: (11.18%) (873/7808)\n",
      "Epoch: 0 | Batch_idx: 70 |  Loss: (4.2815) | Acc: (11.00%) (1000/9088)\n",
      "Epoch: 0 | Batch_idx: 80 |  Loss: (4.0381) | Acc: (10.91%) (1131/10368)\n",
      "Epoch: 0 | Batch_idx: 90 |  Loss: (3.8469) | Acc: (10.83%) (1261/11648)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (3.6926) | Acc: (10.88%) (1406/12928)\n",
      "Epoch: 0 | Batch_idx: 110 |  Loss: (3.5657) | Acc: (10.92%) (1551/14208)\n",
      "Epoch: 0 | Batch_idx: 120 |  Loss: (3.4597) | Acc: (10.97%) (1699/15488)\n",
      "Epoch: 0 | Batch_idx: 130 |  Loss: (3.3700) | Acc: (11.02%) (1848/16768)\n",
      "Epoch: 0 | Batch_idx: 140 |  Loss: (3.2938) | Acc: (11.06%) (1996/18048)\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (3.2272) | Acc: (11.04%) (2133/19328)\n",
      "Epoch: 0 | Batch_idx: 160 |  Loss: (3.1681) | Acc: (11.17%) (2302/20608)\n",
      "Epoch: 0 | Batch_idx: 170 |  Loss: (3.1165) | Acc: (11.21%) (2453/21888)\n",
      "Epoch: 0 | Batch_idx: 180 |  Loss: (3.0701) | Acc: (11.34%) (2628/23168)\n",
      "Epoch: 0 | Batch_idx: 190 |  Loss: (3.0283) | Acc: (11.36%) (2778/24448)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (2.9900) | Acc: (11.46%) (2949/25728)\n",
      "Epoch: 0 | Batch_idx: 210 |  Loss: (2.9552) | Acc: (11.48%) (3101/27008)\n",
      "Epoch: 0 | Batch_idx: 220 |  Loss: (2.9232) | Acc: (11.61%) (3285/28288)\n",
      "Epoch: 0 | Batch_idx: 230 |  Loss: (2.8933) | Acc: (11.77%) (3479/29568)\n",
      "Epoch: 0 | Batch_idx: 240 |  Loss: (2.8647) | Acc: (12.13%) (3741/30848)\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (2.8378) | Acc: (12.43%) (3994/32128)\n",
      "Epoch: 0 | Batch_idx: 260 |  Loss: (2.8118) | Acc: (12.68%) (4237/33408)\n",
      "Epoch: 0 | Batch_idx: 270 |  Loss: (2.7875) | Acc: (12.91%) (4479/34688)\n",
      "Epoch: 0 | Batch_idx: 280 |  Loss: (2.7635) | Acc: (13.21%) (4753/35968)\n",
      "Epoch: 0 | Batch_idx: 290 |  Loss: (2.7416) | Acc: (13.42%) (5000/37248)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (2.7204) | Acc: (13.69%) (5275/38528)\n",
      "Epoch: 0 | Batch_idx: 310 |  Loss: (2.6998) | Acc: (14.01%) (5577/39808)\n",
      "Epoch: 0 | Batch_idx: 320 |  Loss: (2.6801) | Acc: (14.24%) (5852/41088)\n",
      "Epoch: 0 | Batch_idx: 330 |  Loss: (2.6608) | Acc: (14.45%) (6124/42368)\n",
      "Epoch: 0 | Batch_idx: 340 |  Loss: (2.6420) | Acc: (14.67%) (6402/43648)\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (2.6248) | Acc: (14.91%) (6701/44928)\n",
      "Epoch: 0 | Batch_idx: 360 |  Loss: (2.6074) | Acc: (15.11%) (6984/46208)\n",
      "Epoch: 0 | Batch_idx: 370 |  Loss: (2.5920) | Acc: (15.28%) (7255/47488)\n",
      "Epoch: 0 | Batch_idx: 380 |  Loss: (2.5762) | Acc: (15.49%) (7554/48768)\n",
      "Epoch: 0 | Batch_idx: 390 |  Loss: (2.5611) | Acc: (15.67%) (7836/50000)\n",
      "# TEST : Loss: (1.9892) | Acc: (24.58%) (2458/10000)\n",
      "\n",
      "\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (2.0000) | Acc: (22.66%) (29/128)\n",
      "Epoch: 1 | Batch_idx: 10 |  Loss: (2.0010) | Acc: (21.73%) (306/1408)\n",
      "Epoch: 1 | Batch_idx: 20 |  Loss: (1.9726) | Acc: (22.51%) (605/2688)\n",
      "Epoch: 1 | Batch_idx: 30 |  Loss: (1.9620) | Acc: (22.86%) (907/3968)\n",
      "Epoch: 1 | Batch_idx: 40 |  Loss: (1.9599) | Acc: (22.47%) (1179/5248)\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (1.9609) | Acc: (22.40%) (1462/6528)\n",
      "Epoch: 1 | Batch_idx: 60 |  Loss: (1.9532) | Acc: (22.59%) (1764/7808)\n",
      "Epoch: 1 | Batch_idx: 70 |  Loss: (1.9451) | Acc: (22.78%) (2070/9088)\n",
      "Epoch: 1 | Batch_idx: 80 |  Loss: (1.9428) | Acc: (22.89%) (2373/10368)\n",
      "Epoch: 1 | Batch_idx: 90 |  Loss: (1.9385) | Acc: (22.78%) (2653/11648)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (1.9352) | Acc: (22.75%) (2941/12928)\n",
      "Epoch: 1 | Batch_idx: 110 |  Loss: (1.9340) | Acc: (22.83%) (3243/14208)\n",
      "Epoch: 1 | Batch_idx: 120 |  Loss: (1.9324) | Acc: (23.04%) (3569/15488)\n",
      "Epoch: 1 | Batch_idx: 130 |  Loss: (1.9308) | Acc: (23.18%) (3887/16768)\n",
      "Epoch: 1 | Batch_idx: 140 |  Loss: (1.9305) | Acc: (23.18%) (4184/18048)\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (1.9297) | Acc: (23.31%) (4506/19328)\n",
      "Epoch: 1 | Batch_idx: 160 |  Loss: (1.9269) | Acc: (23.45%) (4833/20608)\n",
      "Epoch: 1 | Batch_idx: 170 |  Loss: (1.9287) | Acc: (23.45%) (5133/21888)\n",
      "Epoch: 1 | Batch_idx: 180 |  Loss: (1.9265) | Acc: (23.53%) (5451/23168)\n",
      "Epoch: 1 | Batch_idx: 190 |  Loss: (1.9252) | Acc: (23.50%) (5745/24448)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (1.9225) | Acc: (23.57%) (6063/25728)\n",
      "Epoch: 1 | Batch_idx: 210 |  Loss: (1.9175) | Acc: (23.65%) (6388/27008)\n",
      "Epoch: 1 | Batch_idx: 220 |  Loss: (1.9149) | Acc: (23.80%) (6733/28288)\n",
      "Epoch: 1 | Batch_idx: 230 |  Loss: (1.9150) | Acc: (23.81%) (7039/29568)\n",
      "Epoch: 1 | Batch_idx: 240 |  Loss: (1.9139) | Acc: (23.89%) (7370/30848)\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (1.9133) | Acc: (23.92%) (7684/32128)\n",
      "Epoch: 1 | Batch_idx: 260 |  Loss: (1.9125) | Acc: (24.01%) (8020/33408)\n",
      "Epoch: 1 | Batch_idx: 270 |  Loss: (1.9116) | Acc: (24.11%) (8363/34688)\n",
      "Epoch: 1 | Batch_idx: 280 |  Loss: (1.9107) | Acc: (24.19%) (8702/35968)\n",
      "Epoch: 1 | Batch_idx: 290 |  Loss: (1.9079) | Acc: (24.34%) (9068/37248)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (1.9044) | Acc: (24.40%) (9401/38528)\n",
      "Epoch: 1 | Batch_idx: 310 |  Loss: (1.9013) | Acc: (24.52%) (9759/39808)\n",
      "Epoch: 1 | Batch_idx: 320 |  Loss: (1.8995) | Acc: (24.56%) (10090/41088)\n",
      "Epoch: 1 | Batch_idx: 330 |  Loss: (1.8982) | Acc: (24.61%) (10426/42368)\n",
      "Epoch: 1 | Batch_idx: 340 |  Loss: (1.8972) | Acc: (24.68%) (10772/43648)\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (1.8960) | Acc: (24.69%) (11092/44928)\n",
      "Epoch: 1 | Batch_idx: 360 |  Loss: (1.8939) | Acc: (24.78%) (11450/46208)\n",
      "Epoch: 1 | Batch_idx: 370 |  Loss: (1.8929) | Acc: (24.90%) (11824/47488)\n",
      "Epoch: 1 | Batch_idx: 380 |  Loss: (1.8921) | Acc: (24.94%) (12161/48768)\n",
      "Epoch: 1 | Batch_idx: 390 |  Loss: (1.8899) | Acc: (25.00%) (12501/50000)\n",
      "# TEST : Loss: (1.7676) | Acc: (29.38%) (2938/10000)\n",
      "\n",
      "\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (1.7329) | Acc: (30.47%) (39/128)\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (1.7924) | Acc: (30.33%) (427/1408)\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (1.8128) | Acc: (28.87%) (776/2688)\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (1.8126) | Acc: (28.76%) (1141/3968)\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (1.8155) | Acc: (28.20%) (1480/5248)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (1.8195) | Acc: (28.00%) (1828/6528)\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (1.8127) | Acc: (28.38%) (2216/7808)\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (1.8166) | Acc: (28.58%) (2597/9088)\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (1.8178) | Acc: (28.50%) (2955/10368)\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (1.8157) | Acc: (28.71%) (3344/11648)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (1.8142) | Acc: (28.57%) (3693/12928)\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (1.8130) | Acc: (28.53%) (4053/14208)\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (1.8115) | Acc: (28.54%) (4421/15488)\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (1.8063) | Acc: (28.76%) (4822/16768)\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (1.8063) | Acc: (28.74%) (5187/18048)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (1.8019) | Acc: (28.88%) (5582/19328)\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (1.7977) | Acc: (29.07%) (5990/20608)\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (1.7983) | Acc: (29.08%) (6364/21888)\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (1.7963) | Acc: (29.19%) (6763/23168)\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (1.7965) | Acc: (29.30%) (7163/24448)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (1.7946) | Acc: (29.43%) (7573/25728)\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (1.7928) | Acc: (29.54%) (7977/27008)\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (1.7902) | Acc: (29.69%) (8399/28288)\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (1.7877) | Acc: (29.91%) (8844/29568)\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (1.7856) | Acc: (30.06%) (9272/30848)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (1.7825) | Acc: (30.26%) (9721/32128)\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (1.7791) | Acc: (30.52%) (10195/33408)\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (1.7779) | Acc: (30.64%) (10627/34688)\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (1.7757) | Acc: (30.80%) (11077/35968)\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (1.7732) | Acc: (30.95%) (11528/37248)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (1.7702) | Acc: (31.14%) (11997/38528)\n",
      "Epoch: 2 | Batch_idx: 310 |  Loss: (1.7667) | Acc: (31.33%) (12470/39808)\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (1.7644) | Acc: (31.38%) (12895/41088)\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (1.7628) | Acc: (31.44%) (13321/42368)\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (1.7608) | Acc: (31.55%) (13770/43648)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (1.7580) | Acc: (31.65%) (14221/44928)\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (1.7558) | Acc: (31.75%) (14669/46208)\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (1.7515) | Acc: (31.91%) (15155/47488)\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (1.7482) | Acc: (32.09%) (15650/48768)\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (1.7457) | Acc: (32.23%) (16113/50000)\n",
      "# TEST : Loss: (1.5847) | Acc: (39.40%) (3940/10000)\n",
      "\n",
      "\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (1.5805) | Acc: (38.28%) (49/128)\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (1.6420) | Acc: (37.86%) (533/1408)\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (1.6148) | Acc: (39.51%) (1062/2688)\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (1.6167) | Acc: (39.24%) (1557/3968)\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (1.6144) | Acc: (39.23%) (2059/5248)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (1.6046) | Acc: (39.46%) (2576/6528)\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (1.6034) | Acc: (39.45%) (3080/7808)\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (1.6109) | Acc: (39.25%) (3567/9088)\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (1.6126) | Acc: (39.26%) (4070/10368)\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (1.6104) | Acc: (39.08%) (4552/11648)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (1.6088) | Acc: (39.12%) (5058/12928)\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (1.6021) | Acc: (39.16%) (5564/14208)\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (1.5969) | Acc: (39.39%) (6101/15488)\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (1.5948) | Acc: (39.50%) (6624/16768)\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (1.5891) | Acc: (39.74%) (7173/18048)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (1.5842) | Acc: (39.91%) (7713/19328)\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (1.5838) | Acc: (39.97%) (8237/20608)\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (1.5855) | Acc: (39.89%) (8731/21888)\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (1.5838) | Acc: (39.94%) (9254/23168)\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (1.5808) | Acc: (40.11%) (9807/24448)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (1.5788) | Acc: (40.25%) (10356/25728)\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (1.5783) | Acc: (40.26%) (10873/27008)\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (1.5772) | Acc: (40.33%) (11408/28288)\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (1.5762) | Acc: (40.29%) (11912/29568)\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (1.5731) | Acc: (40.42%) (12470/30848)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (1.5716) | Acc: (40.60%) (13044/32128)\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (1.5682) | Acc: (40.76%) (13618/33408)\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (1.5658) | Acc: (40.90%) (14187/34688)\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (1.5619) | Acc: (41.03%) (14759/35968)\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (1.5602) | Acc: (41.07%) (15298/37248)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (1.5594) | Acc: (41.12%) (15844/38528)\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (1.5582) | Acc: (41.18%) (16392/39808)\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (1.5557) | Acc: (41.26%) (16953/41088)\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (1.5519) | Acc: (41.41%) (17546/42368)\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (1.5499) | Acc: (41.51%) (18118/43648)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (1.5471) | Acc: (41.60%) (18689/44928)\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (1.5456) | Acc: (41.66%) (19250/46208)\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (1.5431) | Acc: (41.76%) (19831/47488)\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (1.5401) | Acc: (41.90%) (20433/48768)\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (1.5388) | Acc: (41.97%) (20986/50000)\n",
      "# TEST : Loss: (1.4896) | Acc: (45.36%) (4536/10000)\n",
      "\n",
      "\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (1.3098) | Acc: (55.47%) (71/128)\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (1.4431) | Acc: (47.23%) (665/1408)\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (1.4320) | Acc: (46.99%) (1263/2688)\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (1.4357) | Acc: (46.57%) (1848/3968)\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (1.4361) | Acc: (46.07%) (2418/5248)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (1.4381) | Acc: (46.23%) (3018/6528)\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (1.4368) | Acc: (46.47%) (3628/7808)\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (1.4369) | Acc: (46.24%) (4202/9088)\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (1.4448) | Acc: (46.15%) (4785/10368)\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (1.4397) | Acc: (46.33%) (5396/11648)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (1.4400) | Acc: (46.24%) (5978/12928)\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (1.4357) | Acc: (46.51%) (6608/14208)\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (1.4330) | Acc: (46.58%) (7215/15488)\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (1.4284) | Acc: (46.74%) (7838/16768)\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (1.4208) | Acc: (46.91%) (8467/18048)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (1.4177) | Acc: (47.01%) (9087/19328)\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (1.4185) | Acc: (47.03%) (9692/20608)\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (1.4177) | Acc: (46.95%) (10276/21888)\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (1.4161) | Acc: (47.09%) (10910/23168)\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (1.4168) | Acc: (47.14%) (11524/24448)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (1.4135) | Acc: (47.25%) (12156/25728)\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (1.4122) | Acc: (47.31%) (12777/27008)\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (1.4079) | Acc: (47.48%) (13430/28288)\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (1.4085) | Acc: (47.53%) (14054/29568)\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (1.4069) | Acc: (47.64%) (14695/30848)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (1.4027) | Acc: (47.78%) (15352/32128)\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (1.4010) | Acc: (47.85%) (15986/33408)\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (1.4013) | Acc: (47.84%) (16596/34688)\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (1.3998) | Acc: (47.89%) (17224/35968)\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (1.3980) | Acc: (47.97%) (17867/37248)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (1.3942) | Acc: (48.15%) (18550/38528)\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (1.3923) | Acc: (48.22%) (19197/39808)\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (1.3896) | Acc: (48.32%) (19853/41088)\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (1.3872) | Acc: (48.42%) (20515/42368)\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (1.3848) | Acc: (48.55%) (21192/43648)\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (1.3824) | Acc: (48.64%) (21852/44928)\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (1.3797) | Acc: (48.75%) (22528/46208)\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (1.3789) | Acc: (48.76%) (23155/47488)\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (1.3780) | Acc: (48.83%) (23811/48768)\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (1.3762) | Acc: (48.91%) (24456/50000)\n",
      "# TEST : Loss: (1.2713) | Acc: (52.99%) (5299/10000)\n",
      "\n",
      "\n",
      "0 hours 1 mins 59 secs for training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:2')\n",
    "model = VisionTransformer(\n",
    "    patch_vec_size=4,\n",
    "    num_patches=\n",
    ")\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss().cuda(device)\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    # model = nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda(device)\n",
    "    print('USE index 2 GPU')\n",
    "\n",
    "\n",
    "train_loss_graph = []\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda(device)), Variable(target.cuda(device))\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        # 모든 gradient를 0으로 set해주는 것은 RNN의 경우를 대비하여 function 자체가 gradient를 accumulate하도록 만들어졌기 때문\n",
    "        optimizer.zero_grad()\n",
    "        # forward()한 값을 반환 \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        # When you call loss.backward(),\n",
    "        # all it does is compute gradient of loss w.r.t all the parameters in loss\n",
    "        # that have requires_grad = True and store them in parameter.grad attribute for every parameter.\n",
    "        # optimizer.step() updates all the parameters based on parameter.grad\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        # torch.max() : (maximum value, index of maximum value) return. \n",
    "        # 1 :  row마다 max계산 (즉, row는 10개의 class를 의미) \n",
    "        # 0 : column마다 max 계산 \n",
    "        total += target.size(0)\n",
    "        # 가장 높은 값이 나온 클래스들과 target(label)을 비교하여 correct에 더함.\n",
    "        correct += predicted.eq(target.data).cpu().sum() \n",
    "        if not(epoch==0 and batch_idx==0):\n",
    "          train_loss_graph.append(train_loss/(batch_idx+1))\n",
    "        if batch_idx % 10 == 0:        \n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "test_loss_graph = []\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda(device)), Variable(target.cuda(device))\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "    test_loss_graph.append(test_loss/(batch_idx+1))\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "      .format(test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "\n",
    "for epoch in range(0, 5): #165):\n",
    "    # if epoch < 80:\n",
    "    #     learning_rate = learning_rate\n",
    "    # elif epoch < 120:\n",
    "    #     learning_rate = learning_rate * 0.1\n",
    "    # else:\n",
    "    #     learning_rate = learning_rate * 0.01\n",
    "    # for param_group in optimizer.param_groups:\n",
    "    #     param_group['learning_rate'] = learning_rate\n",
    "\n",
    "    train(epoch)\n",
    "    test()\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_graph)\n",
    "plt.title('train loss')\n",
    "plt.savefig('tarin_loss_graph.jpg')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(test_loss_graph)\n",
    "plt.title('test loss')\n",
    "plt.savefig('test_loss_graph.jpg')\n",
    "plt.close()\n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65fe116ec29312474b580f4ecbad52a94f46ea3a142b15e85ff8e68848a207e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
